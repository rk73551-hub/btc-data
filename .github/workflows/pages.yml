name: Mirror BTC data to GitHub Pages

on:
  workflow_dispatch:
  schedule:
    - cron: "*/15 * * * *"  # every 15 minutes

permissions:
  contents: write
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: true

env:
  EXEC: https://script.google.com/macros/s/AKfycbzsDjd0fYUiOLnEYnFkPETvXg4VdLXIqSXX5tUNB1oeJ8o2EqzXXjAVezaNXKMf0lWTHQ/exec
  CACHEBUST: ${{ github.run_id }}-${{ github.run_number }}-${{ github.run_attempt }}

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository (default branch)
        uses: actions/checkout@v4

      - name: Create public dir
        run: mkdir -p public

      # --- Sanity: health must return JSON
      - name: Sanity ping (health)
        shell: bash
        run: |
          set -euo pipefail
          tmp="$(mktemp)"; hdr="$(mktemp)"
          curl -sS -L --fail --retry 6 --retry-all-errors --max-time 60 \
            -H "Accept: application/json" \
            --get "${EXEC}" \
            --data-urlencode "mode=health" \
            --data-urlencode "token=${{ secrets.APITOKEN }}" \
            --data-urlencode "cachebust=${CACHEBUST}" \
            -D "$hdr" -o "$tmp"
          grep -qi '^content-type: *application/json' "$hdr" || { echo "Not JSON Content-Type"; cat "$hdr"; exit 1; }
          jq empty "$tmp" || { echo "Invalid JSON body"; cat "$tmp"; exit 1; }
          mv "$tmp" public/health.json

      # --- Latest row (limit 1), include A:N (we'll anchor dashboard to this)
      - name: Fetch latest row
        shell: bash
        run: |
          set -euo pipefail
          tmp="$(mktemp)"; hdr="$(mktemp)"
          curl -sS -L --fail --retry 6 --retry-all-errors --max-time 60 \
            -H "Accept: application/json" \
            --get "${EXEC}" \
            --data-urlencode "mode=ytd" \
            --data-urlencode "limit=1" \
            --data-urlencode "cols=1:14" \
            --data-urlencode "token=${{ secrets.APITOKEN }}" \
            --data-urlencode "cachebust=${CACHEBUST}" \
            -D "$hdr" -o "$tmp"
          grep -qi '^content-type: *application/json' "$hdr" || { echo "Not JSON Content-Type"; cat "$hdr"; exit 1; }
          jq empty "$tmp" || { echo "Invalid JSON body"; cat "$tmp"; exit 1; }
          mv "$tmp" public/latest.json

      # --- Last 24h (limit 24), include A:N
      - name: Fetch last 24h
        shell: bash
        run: |
          set -euo pipefail
          tmp="$(mktemp)"; hdr="$(mktemp)"
          curl -sS -L --fail --retry 6 --retry-all-errors --max-time 60 \
            -H "Accept: application/json" \
            --get "${EXEC}" \
            --data-urlencode "mode=ytd" \
            --data-urlencode "limit=24" \
            --data-urlencode "cols=1:14" \
            --data-urlencode "token=${{ secrets.APITOKEN }}" \
            --data-urlencode "cachebust=${CACHEBUST}" \
            -D "$hdr" -o "$tmp"
          grep -qi '^content-type: *application/json' "$hdr" || { echo "Not JSON Content-Type"; cat "$hdr"; exit 1; }
          jq empty "$tmp" || { echo "Invalid JSON body"; cat "$tmp"; exit 1; }
          mv "$tmp" public/last-24h.json

      # --- YTD since Jan 1 (current year), include A:N
      - name: Fetch YTD
        shell: bash
        run: |
          set -euo pipefail
          tmp="$(mktemp)"; hdr="$(mktemp)"
          curl -sS -L --fail --retry 6 --retry-all-errors --max-time 60 \
            -H "Accept: application/json" \
            --get "${EXEC}" \
            --data-urlencode "mode=ytd" \
            --data-urlencode "since=2025-01-01T00:00:00Z" \
            --data-urlencode "limit=20000" \
            --data-urlencode "cols=1:14" \
            --data-urlencode "token=${{ secrets.APITOKEN }}" \
            --data-urlencode "cachebust=${CACHEBUST}" \
            -D "$hdr" -o "$tmp"
          grep -qi '^content-type: *application/json' "$hdr" || { echo "Not JSON Content-Type"; cat "$hdr"; exit 1; }
          jq empty "$tmp" || { echo "Invalid JSON body"; cat "$tmp"; exit 1; }
          mv "$tmp" public/ytd.json

      # --- 90d dataset (A:N)
      - name: Fetch 90d dataset
        shell: bash
        run: |
          set -euo pipefail
          tmp="$(mktemp)"; hdr="$(mktemp)"
          curl -sS -L --fail --retry 6 --retry-all-errors --max-time 60 \
            -H "Accept: application/json" \
            --get "${EXEC}" \
            --data-urlencode "mode=90d" \
            --data-urlencode "limit=2160" \
            --data-urlencode "cols=1:14" \
            --data-urlencode "token=${{ secrets.APITOKEN }}" \
            --data-urlencode "cachebust=${CACHEBUST}" \
            -D "$hdr" -o "$tmp"
          grep -qi '^content-type: *application/json' "$hdr" || { echo "Not JSON Content-Type"; cat "$hdr"; exit 1; }
          jq empty "$tmp" || { echo "Invalid JSON body"; cat "$tmp"; exit 1; }
          mv "$tmp" public/90d.json

      # --- 2023 archive (client-side filter with jq; requires backfill)
      - name: Build 2023 archive
        shell: bash
        run: |
          set -euo pipefail
          curl -sS -L --fail --retry 6 --retry-all-errors --max-time 90 \
            -H "Accept: application/json" \
            --get "${EXEC}" \
            --data-urlencode "mode=ytd" \
            --data-urlencode "since=2023-01-01T00:00:00Z" \
            --data-urlencode "limit=30000" \
            --data-urlencode "cols=1:14" \
            --data-urlencode "token=${{ secrets.APITOKEN }}" \
            --data-urlencode "cachebust=${CACHEBUST}" \
            -o public/_tmp2023.json
          jq '{rows: [ .rows[]
               | select(.time_utc >= "2023-01-01T00:00:00Z" and .time_utc < "2024-01-01T00:00:00.000Z") ] }' \
            public/_tmp2023.json > public/2023.json
          rm -f public/_tmp2023.json

      # --- 2024 archive
      - name: Build 2024 archive
        shell: bash
        run: |
          set -euo pipefail
          curl -sS -L --fail --retry 6 --retry-all-errors --max-time 90 \
            -H "Accept: application/json" \
            --get "${EXEC}" \
            --data-urlencode "mode=ytd" \
            --data-urlencode "since=2024-01-01T00:00:00Z" \
            --data-urlencode "limit=30000" \
            --data-urlencode "cols=1:14" \
            --data-urlencode "token=${{ secrets.APITOKEN }}" \
            --data-urlencode "cachebust=${CACHEBUST}" \
            -o public/_tmp2024.json
          jq '{rows: [ .rows[]
               | select(.time_utc >= "2024-01-01T00:00:00Z" and .time_utc < "2025-01-01T00:00:00.000Z") ] }' \
            public/_tmp2024.json > public/2024.json
          rm -f public/_tmp2024.json

      # --- Dashboard summary anchored to the latest candle (~atomic snapshot)
      - name: Fetch dashboard summary (anchored)
        shell: bash
        run: |
          set -euo pipefail
          anchor=$(jq -r '.rows[0].time_utc' public/latest.json)
          tmp="$(mktemp)"; hdr="$(mktemp)"
          curl -sS -L --fail --retry 6 --retry-all-errors --max-time 60 \
            -H "Accept: application/json" \
            --get "${EXEC}" \
            --data-urlencode "mode=dashboard" \
            --data-urlencode "anchor_time=${anchor}" \
            --data-urlencode "token=${{ secrets.APITOKEN }}" \
            --data-urlencode "cachebust=${CACHEBUST}" \
            -D "$hdr" -o "$tmp"
          grep -qi '^content-type: *application/json' "$hdr" || { echo "Not JSON Content-Type (dashboard)"; cat "$hdr"; exit 1; }
          jq empty "$tmp" || { echo "Invalid JSON body (dashboard)"; cat "$tmp"; exit 1; }
          mv "$tmp" public/dashboard.json
          # Assert equality with latest.json to guarantee atomicity
          d_close=$(jq -r '.latest_close' public/dashboard.json)
          d_time=$(jq -r '.latest_time_utc' public/dashboard.json)
          l_close=$(jq -r '.rows[0].close' public/latest.json)
          l_time=$(jq -r '.rows[0].time_utc' public/latest.json)
          test "$d_close" = "$l_close" && test "$d_time" = "$l_time"

      - name: Write timestamp
        run: date -u +"%Y-%m-%dT%H:%M:%SZ" > public/timestamp.txt

      # Commit JSONs to gh-pages
      - name: Prepare gh-pages branch
        shell: bash
        run: |
          set -e
          git fetch origin gh-pages || true
          if git show-ref --verify --quiet refs/remotes/origin/gh-pages; then
            git checkout -B gh-pages origin/gh-pages
          else
            git checkout --orphan gh-pages
            git reset --hard
          fi
          cp -f public/latest.json public/last-24h.json public/ytd.json public/90d.json public/dashboard.json public/2023.json public/2024.json public/timestamp.txt .
          git add latest.json last-24h.json ytd.json 90d.json dashboard.json 2023.json 2024.json timestamp.txt
          git config user.name "github-actions"
          git config user.email "actions@github.com"
          git commit -m "Update mirrored data (anchored dashboard + yearly archives)" || echo "No changes to commit"
          git push origin gh-pages

      # Also publish to Pages (artifact = /public)
      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: public

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - id: deployment
        uses: actions/deploy-pages@v4
